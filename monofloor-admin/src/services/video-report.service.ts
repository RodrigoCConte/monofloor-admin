import ffmpeg from 'fluent-ffmpeg';
import path from 'path';
import fs from 'fs/promises';
import sharp from 'sharp';
import PDFDocument from 'pdfkit';
import OpenAI from 'openai';
import docxReportService from './docx-report.service';

// Configure FFmpeg path
const ffmpegStatic = require('ffmpeg-static');
ffmpeg.setFfmpegPath(ffmpegStatic);

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
});

interface VideoReportOptions {
    videoPath: string;
    projectName: string;
    technicianName: string;
    visitDate: string;
    visitPurpose: string;
    observations?: string;
    frameInterval?: number; // segundos
    maxFrames?: number;
    analysisPrompt?: string;
    outputFormat?: 'pdf' | 'docx'; // Formato de sa√≠da
    clientName?: string; // Para DOCX
    address?: string; // Para DOCX
}

interface ExtractedFrame {
    path: string;
    timestamp: number;
    buffer: Buffer;
}

interface FrameAnalysis {
    frame: ExtractedFrame;
    analysis: string;
}

interface TopicGroup {
    topic: string;
    description: string;
    frameAnalyses: FrameAnalysis[];
}

interface TranscriptionSegment {
    text: string;
    start: number; // timestamp em segundos
    end: number;
}

interface AudioTopicTimestamp {
    topic: string;
    description: string;
    timestamps: number[]; // momentos espec√≠ficos para extrair frames
    narration: string; // o que foi dito sobre este t√≥pico
}

export class VideoReportService {
    private tempDir = path.join(__dirname, '../../temp');

    constructor() {
        this.ensureTempDir();
    }

    private async ensureTempDir() {
        try {
            await fs.mkdir(this.tempDir, { recursive: true });
        } catch (error) {
            console.error('Erro ao criar diret√≥rio temp:', error);
        }
    }

    /**
     * Extrai √°udio do v√≠deo usando FFmpeg
     * Retorna o caminho para o arquivo de √°udio WAV
     */
    private extractAudio(videoPath: string): Promise<string> {
        return new Promise((resolve, reject) => {
            const audioPath = path.join(this.tempDir, `audio_${Date.now()}.wav`);

            console.log('[VideoReport] Extraindo √°udio do v√≠deo...');

            ffmpeg(videoPath)
                .noVideo()
                .audioCodec('pcm_s16le')
                .audioFrequency(16000) // Whisper funciona melhor com 16kHz
                .audioChannels(1) // Mono
                .output(audioPath)
                .on('end', () => {
                    console.log('[VideoReport] ‚úì √Åudio extra√≠do:', audioPath);
                    resolve(audioPath);
                })
                .on('error', (err) => {
                    reject(new Error(`Erro ao extrair √°udio: ${err.message}`));
                })
                .run();
        });
    }

    /**
     * Transcreve √°udio usando OpenAI Whisper com timestamps
     */
    private async transcribeAudio(audioPath: string): Promise<TranscriptionSegment[]> {
        console.log('[VideoReport] Transcrevendo √°udio com Whisper...');

        try {
            const audioFile = await fs.readFile(audioPath);
            const audioBlob = new Blob([audioFile], { type: 'audio/wav' });

            // Criar File object do Blob
            const audioFileObject = new File([audioBlob], 'audio.wav', { type: 'audio/wav' });

            const response = await openai.audio.transcriptions.create({
                file: audioFileObject,
                model: 'whisper-1',
                language: 'pt',
                response_format: 'verbose_json',
                timestamp_granularities: ['segment']
            });

            console.log('[VideoReport] ‚úì Transcri√ß√£o conclu√≠da');
            console.log('[VideoReport] Texto completo:', response.text);

            // Converter response.segments para TranscriptionSegment[]
            const segments: TranscriptionSegment[] = (response.segments || []).map((seg: any) => ({
                text: seg.text,
                start: seg.start,
                end: seg.end
            }));

            console.log(`[VideoReport] ${segments.length} segmentos identificados`);

            return segments;
        } catch (error: any) {
            console.error('[VideoReport] Erro ao transcrever √°udio:', error.message);
            throw error;
        }
    }

    /**
     * Analisa a transcri√ß√£o e identifica t√≥picos mencionados com seus timestamps
     */
    private async analyzeTranscription(segments: TranscriptionSegment[]): Promise<AudioTopicTimestamp[]> {
        console.log('[VideoReport] Analisando transcri√ß√£o para identificar t√≥picos...');

        const fullTranscription = segments.map((seg, i) => {
            return `[${this.formatTimestamp(seg.start)} - ${this.formatTimestamp(seg.end)}]: ${seg.text}`;
        }).join('\n');

        console.log('[VideoReport] Transcri√ß√£o completa:\n', fullTranscription);

        try {
            const response = await openai.chat.completions.create({
                model: 'gpt-4o',
                messages: [
                    {
                        role: 'user',
                        content: `Voc√™ √© um especialista em an√°lise de relat√≥rios t√©cnicos da Monofloor Revestimentos.

Analise esta transcri√ß√£o de √°udio de uma vistoria t√©cnica e identifique os T√ìPICOS mencionados pelo t√©cnico.

TRANSCRI√á√ÉO COM TIMESTAMPS:
${fullTranscription}

TAREFA:
1. Identifique os principais T√ìPICOS t√©cnicos mencionados (ex: "Banheiros", "Cer√¢micas", "Rodap√©s", "Impermeabiliza√ß√£o", etc.)
2. Para cada t√≥pico, identifique os timestamps EXATOS (em segundos) onde o t√©cnico menciona ou aponta problemas
3. Extraia a narra√ß√£o relevante (o que foi dito sobre cada t√≥pico)
4. Crie uma descri√ß√£o t√©cnica do problema mencionado

REGRAS CR√çTICAS:
- Cada t√≥pico deve ter pelo menos 1 timestamp, m√°ximo 5 timestamps
- Use APENAS timestamps que aparecem na transcri√ß√£o acima (ex: se v√™ [00:15 - 00:23], use 15 ou 23)
- NUNCA invente timestamps que n√£o existem na transcri√ß√£o
- O timestamp m√°ximo √© o √∫ltimo que aparece na transcri√ß√£o
- Foque em momentos onde o t√©cnico aponta problemas, medi√ß√µes ou condi√ß√µes importantes
- Se o t√©cnico mencionar "aqui", "esse", "esta √°rea", identifique o timestamp exato desse segmento

Responda APENAS com JSON puro (sem markdown, sem s√≠mbolos extras):
{
  "topics": [
    {
      "topic": "Nome do T√≥pico",
      "description": "Descri√ß√£o t√©cnica do problema",
      "timestamps": [10.5, 25.3, 40.1],
      "narration": "O que foi dito sobre este t√≥pico"
    }
  ]
}`
                    }
                ],
                max_tokens: 2000,
                temperature: 0.3
            });

            const content = response.choices[0]?.message?.content || '{"topics": []}';

            // Remover markdown code blocks se existirem
            const cleanContent = content.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();

            let parsed: { topics: AudioTopicTimestamp[] };

            try {
                parsed = JSON.parse(cleanContent);
            } catch (error) {
                console.error('[VideoReport] Erro ao parsear JSON da an√°lise de transcri√ß√£o');
                console.error('[VideoReport] Conte√∫do recebido:', cleanContent);

                // Fallback: criar um t√≥pico gen√©rico com todos os timestamps
                const allTimestamps = segments.map(seg => seg.start);
                parsed = {
                    topics: [{
                        topic: 'An√°lise Geral',
                        description: 'Condi√ß√µes gerais encontradas durante a visita',
                        timestamps: allTimestamps.slice(0, 10), // Pegar primeiros 10 timestamps
                        narration: segments.map(seg => seg.text).join(' ')
                    }]
                };
            }

            console.log(`[VideoReport] ${parsed.topics.length} t√≥picos identificados da narra√ß√£o:`);
            parsed.topics.forEach(topic => {
                console.log(`  - ${topic.topic} (${topic.timestamps.length} momentos identificados)`);
            });

            return parsed.topics;
        } catch (error: any) {
            console.error('[VideoReport] Erro ao analisar transcri√ß√£o:', error.message);
            throw error;
        }
    }

    /**
     * Extrai frames espec√≠ficos em timestamps determinados
     */
    private async extractFramesAtTimestamps(
        videoPath: string,
        timestamps: number[]
    ): Promise<ExtractedFrame[]> {
        console.log(`[VideoReport] Extraindo ${timestamps.length} frames em timestamps espec√≠ficos...`);

        const frames: ExtractedFrame[] = [];

        for (let i = 0; i < timestamps.length; i++) {
            const timestamp = timestamps[i];
            const uniqueId = `${Date.now()}_${i}`;
            const filename = `frame_${uniqueId}.jpg`;
            const framePath = path.join(this.tempDir, filename);

            try {
                // Usar seekInput e frames(1) para extrair um √∫nico frame
                await new Promise<void>((resolve, reject) => {
                    ffmpeg(videoPath)
                        .seekInput(timestamp)
                        .frames(1)
                        .output(framePath)
                        .on('end', () => resolve())
                        .on('error', (err) => reject(err))
                        .run();
                });

                // Aguardar um pouco para garantir que o arquivo foi escrito
                await new Promise(resolve => setTimeout(resolve, 200));

                // Verificar se o arquivo existe antes de ler
                try {
                    await fs.access(framePath);
                } catch (error) {
                    throw new Error(`Frame file not found: ${framePath}`);
                }

                const buffer = await fs.readFile(framePath);

                frames.push({
                    path: framePath,
                    timestamp: timestamp,
                    buffer
                });

                console.log(`[VideoReport] ‚úì Frame extra√≠do em ${this.formatTimestamp(timestamp)} -> ${filename}`);
            } catch (error: any) {
                console.error(`[VideoReport] Erro ao extrair frame em ${timestamp}s:`, error.message);
            }
        }

        return frames;
    }

    /**
     * Processa v√≠deo e gera relat√≥rio (PDF ou DOCX) com AN√ÅLISE AUDIO-FIRST
     */
    async generateReport(options: VideoReportOptions): Promise<Buffer> {
        const {
            videoPath,
            projectName,
            technicianName,
            visitDate,
            visitPurpose,
            observations = '',
            analysisPrompt,
            outputFormat = 'pdf',
            clientName,
            address
        } = options;

        console.log('[VideoReport] ========================================');
        console.log('[VideoReport] SISTEMA AUDIO-FIRST (NOVA ARQUITETURA)');
        console.log('[VideoReport] ========================================');
        console.log('[VideoReport] V√≠deo:', videoPath);
        console.log('[VideoReport] Projeto:', projectName);
        console.log('[VideoReport] Formato:', outputFormat.toUpperCase());

        let audioPath: string | null = null;

        try {
            // FASE 1: Extrair √°udio do v√≠deo
            console.log('\n[VideoReport] üéµ Fase 1: Extra√ß√£o de √°udio...');
            audioPath = await this.extractAudio(videoPath);

            // FASE 2: Transcrever √°udio com timestamps
            console.log('\n[VideoReport] üó£Ô∏è Fase 2: Transcri√ß√£o com Whisper...');
            const transcriptionSegments = await this.transcribeAudio(audioPath);
            console.log(`[VideoReport] ‚úì ${transcriptionSegments.length} segmentos transcritos`);

            // FASE 3: Analisar transcri√ß√£o e identificar t√≥picos com timestamps
            console.log('\n[VideoReport] üîç Fase 3: Identificando t√≥picos da narra√ß√£o...');
            const audioTopics = await this.analyzeTranscription(transcriptionSegments);
            console.log(`[VideoReport] ‚úì ${audioTopics.length} t√≥picos identificados`);

            // FASE 4: Extrair frames nos momentos mencionados
            console.log('\n[VideoReport] üé¨ Fase 4: Extraindo frames nos momentos mencionados...');
            const topicGroups: TopicGroup[] = [];

            for (const audioTopic of audioTopics) {
                console.log(`[VideoReport] Processando t√≥pico: ${audioTopic.topic}`);

                // Extrair frames nos timestamps identificados
                const frames = await this.extractFramesAtTimestamps(videoPath, audioTopic.timestamps);

                if (frames.length === 0) {
                    console.warn(`[VideoReport] Nenhum frame extra√≠do para t√≥pico: ${audioTopic.topic}`);
                    continue;
                }

                // FASE 5: Analisar frames correlacionando com o √°udio
                console.log(`[VideoReport] Analisando ${frames.length} frames com correla√ß√£o de √°udio...`);
                const frameAnalyses: FrameAnalysis[] = [];

                for (const frame of frames) {
                    const base64Image = frame.buffer.toString('base64');

                    const technicalPrompt = `Voc√™ √© um especialista t√©cnico da Monofloor Revestimentos analisando uma imagem de vistoria.

O T√âCNICO DISSE: "${audioTopic.narration}"

TAREFA:
Analise esta imagem e CONFIRME/DETALHE o que o t√©cnico narrou. Descreva tecnicamente o que voc√™ v√™ que corresponde √† narra√ß√£o.

FOCO:
- Condi√ß√µes do substrato (concreto, cer√¢mica, nivelamento, trincas)
- Problemas identificados (umidade, desn√≠veis, fissuras, rejuntes deteriorados)
- Medi√ß√µes ou detalhes t√©cnicos vis√≠veis
- Requisitos t√©cnicos necess√°rios (resist√™ncia, prepara√ß√£o, produtos)

ESTILO: T√©cnico, formal, objetivo. Use termos como "resist√™ncia √† compress√£o", "substrato", "ader√™ncia", "nivelamento".

Responda em 3-5 linhas de texto corrido sem s√≠mbolos ou markdown.`;

                    try {
                        const response = await openai.chat.completions.create({
                            model: 'gpt-4o',
                            messages: [
                                {
                                    role: 'user',
                                    content: [
                                        { type: 'text', text: technicalPrompt },
                                        {
                                            type: 'image_url',
                                            image_url: {
                                                url: `data:image/jpeg;base64,${base64Image}`,
                                                detail: 'high'
                                            }
                                        }
                                    ]
                                }
                            ],
                            max_tokens: 300,
                            temperature: 0.4
                        });

                        const analysis = response.choices[0]?.message?.content || 'N√£o foi poss√≠vel analisar esta imagem.';

                        frameAnalyses.push({
                            frame,
                            analysis
                        });

                        console.log(`[VideoReport] ‚úì Frame ${this.formatTimestamp(frame.timestamp)} analisado`);
                    } catch (error: any) {
                        console.error(`[VideoReport] Erro ao analisar frame ${frame.timestamp}s:`, error.message);
                    }

                    // Aguardar entre an√°lises
                    await new Promise(resolve => setTimeout(resolve, 500));
                }

                topicGroups.push({
                    topic: audioTopic.topic,
                    description: audioTopic.description,
                    frameAnalyses
                });
            }

            console.log(`[VideoReport] ‚úì ${topicGroups.length} t√≥picos processados com frames`);

            // FASE 6: Gerar relat√≥rio no formato escolhido
            let reportBuffer: Buffer;

            if (outputFormat === 'docx') {
                console.log('\n[VideoReport] üìÑ Fase 6: Gerando DOCX Monofloor...');
                reportBuffer = await docxReportService.generateDocxReport({
                    projectName,
                    technicianName,
                    visitDate,
                    clientName: clientName || projectName,
                    address: address || '',
                    topicGroups
                });
                console.log('[VideoReport] ‚úì DOCX gerado com sucesso');
            } else {
                console.log('\n[VideoReport] üìÑ Fase 6: Gerando PDF Monofloor...');
                reportBuffer = await this.generateMonofloorPDF({
                    projectName,
                    technicianName,
                    visitDate,
                    visitPurpose,
                    observations,
                    topicGroups
                });
                console.log('[VideoReport] ‚úì PDF gerado com sucesso');
            }

            // FASE 7: Limpar arquivos tempor√°rios
            console.log('\n[VideoReport] üßπ Fase 7: Limpando arquivos tempor√°rios...');
            for (const topicGroup of topicGroups) {
                await this.cleanupFrames(topicGroup.frameAnalyses.map(fa => fa.frame));
            }

            if (audioPath) {
                try {
                    await fs.unlink(audioPath);
                    console.log('[VideoReport] ‚úì √Åudio tempor√°rio removido');
                } catch (error) {
                    console.error('[VideoReport] Erro ao remover √°udio:', error);
                }
            }

            console.log('[VideoReport] ========================================');
            console.log('[VideoReport] ‚úÖ RELAT√ìRIO CONCLU√çDO COM SUCESSO!');
            console.log('[VideoReport] ========================================\n');

            return reportBuffer;

        } catch (error) {
            console.error('[VideoReport] ‚ùå ERRO:', error);

            // Limpar √°udio em caso de erro
            if (audioPath) {
                try {
                    await fs.unlink(audioPath);
                } catch (err) {
                    // Ignorar
                }
            }

            throw error;
        }
    }

    /**
     * Extrai frames do v√≠deo usando FFmpeg com sele√ß√£o inteligente
     * Primeiro extrai muitos frames, depois usa AI para selecionar os relevantes
     */
    private async extractFrames(
        videoPath: string,
        intervalSeconds: number,
        maxFrames: number
    ): Promise<ExtractedFrame[]> {
        console.log('[VideoReport] Fase 1: Extraindo frames candidatos...');

        // Extrair frames a cada 3 segundos (mais denso para n√£o perder momentos importantes)
        const candidateInterval = 3;
        const candidateFrames = await this.extractAllFrames(videoPath, candidateInterval);

        console.log(`[VideoReport] ${candidateFrames.length} frames candidatos extra√≠dos`);

        // Fase 2: Sele√ß√£o inteligente dos frames mais relevantes
        console.log('[VideoReport] Fase 2: Selecionando frames relevantes com IA...');
        const selectedFrames = await this.selectRelevantFrames(candidateFrames, maxFrames);

        // Limpar frames n√£o selecionados
        const selectedPaths = new Set(selectedFrames.map(f => f.path));
        for (const frame of candidateFrames) {
            if (!selectedPaths.has(frame.path)) {
                try {
                    await fs.unlink(frame.path);
                } catch (error) {
                    // Ignorar erros ao deletar
                }
            }
        }

        console.log(`[VideoReport] ${selectedFrames.length} frames relevantes selecionados`);
        return selectedFrames;
    }

    /**
     * Extrai todos os frames em um intervalo fixo
     */
    private extractAllFrames(
        videoPath: string,
        intervalSeconds: number
    ): Promise<ExtractedFrame[]> {
        return new Promise((resolve, reject) => {
            const frames: ExtractedFrame[] = [];
            const maxCandidates = 100; // Limite de frames candidatos

            ffmpeg(videoPath)
                .on('end', async () => {
                    try {
                        // Ler arquivos gerados
                        const files = await fs.readdir(this.tempDir);
                        const frameFiles = files
                            .filter(f => f.startsWith('frame_') && f.endsWith('.jpg'))
                            .sort()
                            .slice(0, maxCandidates);

                        // Carregar buffers
                        for (let i = 0; i < frameFiles.length; i++) {
                            const framePath = path.join(this.tempDir, frameFiles[i]);
                            const buffer = await fs.readFile(framePath);

                            frames.push({
                                path: framePath,
                                timestamp: i * intervalSeconds,
                                buffer
                            });
                        }

                        resolve(frames);
                    } catch (error) {
                        reject(error);
                    }
                })
                .on('error', (err) => {
                    reject(new Error(`Erro ao extrair frames: ${err.message}`));
                })
                .screenshots({
                    folder: this.tempDir,
                    filename: 'frame_%04d.jpg',
                    timestamps: Array.from({ length: maxCandidates }, (_, i) => i * intervalSeconds)
                });
        });
    }

    /**
     * Seleciona frames relevantes usando GPT-4 Vision
     * Crit√©rios: mudan√ßas de cena, problemas vis√≠veis, gestos indicando pontos importantes
     */
    private async selectRelevantFrames(
        candidateFrames: ExtractedFrame[],
        maxFrames: number
    ): Promise<ExtractedFrame[]> {
        const relevanceScores: Array<{ frame: ExtractedFrame; score: number; reason: string }> = [];

        // Avaliar relev√¢ncia em lotes de 5
        const batchSize = 5;
        for (let i = 0; i < candidateFrames.length; i += batchSize) {
            const batch = candidateFrames.slice(i, i + batchSize);

            const batchPromises = batch.map(async (frame) => {
                try {
                    const base64Image = frame.buffer.toString('base64');

                    const response = await openai.chat.completions.create({
                        model: 'gpt-4o',
                        messages: [
                            {
                                role: 'user',
                                content: [
                                    {
                                        type: 'text',
                                        text: `Analise esta imagem de obra e avalie sua RELEV√ÇNCIA para um relat√≥rio t√©cnico de visita.

Atribua uma nota de 0 a 10, onde:
- 10 = Extremamente relevante (problemas graves, condi√ß√µes ruins, aplica√ß√£o incorreta, medi√ß√µes vis√≠veis, detalhes t√©cnicos importantes)
- 7-9 = Muito relevante (√°reas com problemas menores, prepara√ß√£o de substrato, aplica√ß√£o em andamento)
- 4-6 = Moderadamente relevante (√°reas em bom estado, vis√£o geral do ambiente)
- 1-3 = Pouco relevante (imagens borradas, transi√ß√µes, movimentos, nada t√©cnico)
- 0 = Irrelevante (totalmente borrada, sem informa√ß√£o t√©cnica)

Responda APENAS com um JSON no formato:
{"score": X, "reason": "breve explica√ß√£o t√©cnica"}

Foque em: problemas estruturais, condi√ß√µes do substrato, qualidade de aplica√ß√£o, medi√ß√µes, √°reas problem√°ticas.`
                                    },
                                    {
                                        type: 'image_url',
                                        image_url: {
                                            url: `data:image/jpeg;base64,${base64Image}`,
                                            detail: 'low' // Usar low para economizar tokens
                                        }
                                    }
                                ]
                            }
                        ],
                        max_tokens: 100,
                        temperature: 0.3 // Baixa temperatura para respostas consistentes
                    });

                    const content = response.choices[0]?.message?.content || '{"score": 0, "reason": "Erro"}';

                    try {
                        const parsed = JSON.parse(content);
                        return {
                            frame,
                            score: parsed.score || 0,
                            reason: parsed.reason || 'Sem motivo'
                        };
                    } catch {
                        // Se n√£o conseguir parsear JSON, tentar extrair score do texto
                        const scoreMatch = content.match(/score["\s:]+(\d+)/i);
                        const score = scoreMatch ? parseInt(scoreMatch[1]) : 0;
                        return {
                            frame,
                            score,
                            reason: content.substring(0, 100)
                        };
                    }
                } catch (error: any) {
                    console.error(`Erro ao avaliar frame ${frame.timestamp}s:`, error.message);
                    return {
                        frame,
                        score: 0,
                        reason: 'Erro na avalia√ß√£o'
                    };
                }
            });

            const batchResults = await Promise.all(batchPromises);
            relevanceScores.push(...batchResults);

            // Aguardar entre lotes
            if (i + batchSize < candidateFrames.length) {
                await new Promise(resolve => setTimeout(resolve, 1000));
            }
        }

        // Ordenar por score e pegar os top N
        const topFrames = relevanceScores
            .sort((a, b) => b.score - a.score)
            .slice(0, maxFrames)
            .sort((a, b) => a.frame.timestamp - b.frame.timestamp); // Reordenar por timestamp

        console.log('[VideoReport] Frames selecionados:');
        topFrames.forEach(({ frame, score, reason }) => {
            console.log(`  - ${this.formatTimestamp(frame.timestamp)} | Score: ${score}/10 | ${reason}`);
        });

        return topFrames.map(item => item.frame);
    }

    /**
     * Analisa frames usando GPT-4 Vision com prompt t√©cnico e focado em problemas
     */
    private async analyzeFrames(
        frames: ExtractedFrame[],
        prompt?: string
    ): Promise<FrameAnalysis[]> {
        const analyses: FrameAnalysis[] = [];

        const technicalPrompt = prompt || `Voc√™ √© um especialista t√©cnico da Monofloor Revestimentos, analisando condi√ß√µes de obra para aplica√ß√£o de piso monol√≠tico STELION.

Analise esta imagem de forma T√âCNICA e OBJETIVA:

1. **Identifique o ambiente** (ex: banheiro, cozinha, sala, √°rea externa)
2. **Condi√ß√µes do substrato**: tipo de base (concreto, cer√¢mica, etc.), umidade, nivelamento, trincas
3. **Problemas identificados**: desn√≠veis, fissuras, manchas de umidade, cer√¢micas soltas, rejuntes deteriorados
4. **Requisitos t√©cnicos**: resist√™ncia necess√°ria (ex: 20 MPa), prepara√ß√£o necess√°ria, produtos indicados
5. **Observa√ß√µes importantes**: medi√ß√µes vis√≠veis, detalhes cr√≠ticos, √°reas que precisam aten√ß√£o especial

**Estilo de escrita**: Formal, t√©cnico, direto. Use termos como "resist√™ncia √† compress√£o", "substrato", "ader√™ncia", "nivelamento".

Responda em 3-5 linhas de texto t√©cnico corrido.`;

        // Processar em lotes de 5
        const batchSize = 5;
        for (let i = 0; i < frames.length; i += batchSize) {
            const batch = frames.slice(i, i + batchSize);

            const batchPromises = batch.map(async (frame) => {
                try {
                    const base64Image = frame.buffer.toString('base64');

                    const response = await openai.chat.completions.create({
                        model: 'gpt-4o',
                        messages: [
                            {
                                role: 'user',
                                content: [
                                    { type: 'text', text: technicalPrompt },
                                    {
                                        type: 'image_url',
                                        image_url: {
                                            url: `data:image/jpeg;base64,${base64Image}`,
                                            detail: 'high'
                                        }
                                    }
                                ]
                            }
                        ],
                        max_tokens: 300,
                        temperature: 0.4 // Pouca criatividade, mais t√©cnico
                    });

                    const analysis = response.choices[0]?.message?.content || 'N√£o foi poss√≠vel analisar esta imagem.';

                    return {
                        frame,
                        analysis
                    };
                } catch (error: any) {
                    console.error(`Erro ao analisar frame ${frame.timestamp}s:`, error.message);
                    return {
                        frame,
                        analysis: 'Erro ao processar esta imagem.'
                    };
                }
            });

            const batchResults = await Promise.all(batchPromises);
            analyses.push(...batchResults);

            // Aguardar entre lotes
            if (i + batchSize < frames.length) {
                await new Promise(resolve => setTimeout(resolve, 1000));
            }
        }

        return analyses;
    }

    /**
     * Agrupa an√°lises de frames por t√≥picos sem√¢nticos
     * Usa GPT-4 para identificar temas comuns e agrupar frames relacionados
     */
    private async groupFramesByTopics(analyses: FrameAnalysis[]): Promise<TopicGroup[]> {
        console.log('[VideoReport] Fase 3: Agrupando frames por t√≥picos sem√¢nticos...');

        // Criar resumo de todas as an√°lises para enviar ao GPT
        const analysesText = analyses.map((item, index) => {
            return `[Frame ${index + 1} - ${this.formatTimestamp(item.frame.timestamp)}]: ${item.analysis}`;
        }).join('\n\n');

        try {
            const response = await openai.chat.completions.create({
                model: 'gpt-4o',
                messages: [
                    {
                        role: 'user',
                        content: `Voc√™ √© um especialista t√©cnico da Monofloor Revestimentos, organizando um relat√≥rio de visita t√©cnica.

Analise estas ${analyses.length} observa√ß√µes de frames de v√≠deo e agrupe-as em T√ìPICOS T√âCNICOS.

OBSERVA√á√ïES:
${analysesText}

TAREFA:
1. Identifique os principais T√ìPICOS t√©cnicos abordados (ex: "Banheiros", "Condi√ß√µes das Cer√¢micas", "√Årea Externa", "Problemas Estruturais", etc.)
2. Para cada t√≥pico, liste os n√∫meros dos frames que pertencem a ele
3. Crie uma descri√ß√£o t√©cnica curta (1-2 linhas) para cada t√≥pico

REGRAS:
- M√≠nimo de 2 t√≥picos, m√°ximo de 6 t√≥picos
- Um frame pode pertencer a apenas UM t√≥pico (escolha o mais relevante)
- Use nomenclatura t√©cnica e profissional
- Ordene por ordem l√≥gica de inspe√ß√£o (entrada ‚Üí ambientes internos ‚Üí problemas espec√≠ficos)

Responda APENAS com um JSON no formato:
{
  "topics": [
    {
      "topic": "Nome do T√≥pico",
      "description": "Breve descri√ß√£o t√©cnica",
      "frameNumbers": [1, 3, 5]
    }
  ]
}

IMPORTANTE: Todos os ${analyses.length} frames devem ser distribu√≠dos entre os t√≥picos.`
                    }
                ],
                max_tokens: 1000,
                temperature: 0.3
            });

            const content = response.choices[0]?.message?.content || '{"topics": []}';

            let parsed: { topics: Array<{ topic: string; description: string; frameNumbers: number[] }> };

            try {
                // Tentar extrair JSON do conte√∫do
                const jsonMatch = content.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    parsed = JSON.parse(jsonMatch[0]);
                } else {
                    throw new Error('Nenhum JSON encontrado');
                }
            } catch (error) {
                console.error('[VideoReport] Erro ao parsear agrupamento, usando agrupamento padr√£o');
                // Fallback: criar um √∫nico t√≥pico com todos os frames
                parsed = {
                    topics: [{
                        topic: 'An√°lise Geral da Obra',
                        description: 'Condi√ß√µes gerais encontradas durante a visita t√©cnica',
                        frameNumbers: analyses.map((_, i) => i + 1)
                    }]
                };
            }

            // Converter frameNumbers em frameAnalyses
            const topicGroups: TopicGroup[] = parsed.topics.map(topicData => {
                const frameAnalyses = topicData.frameNumbers
                    .map(num => analyses[num - 1])
                    .filter(Boolean); // Remover undefined

                return {
                    topic: topicData.topic,
                    description: topicData.description,
                    frameAnalyses
                };
            }).filter(group => group.frameAnalyses.length > 0); // Remover grupos vazios

            console.log(`[VideoReport] ${topicGroups.length} t√≥picos identificados:`);
            topicGroups.forEach(group => {
                console.log(`  - ${group.topic} (${group.frameAnalyses.length} frames)`);
            });

            return topicGroups;

        } catch (error: any) {
            console.error('[VideoReport] Erro ao agrupar por t√≥picos:', error.message);

            // Fallback: retornar todas as an√°lises em um √∫nico grupo
            return [{
                topic: 'An√°lise Geral da Obra',
                description: 'Condi√ß√µes gerais encontradas durante a visita t√©cnica',
                frameAnalyses: analyses
            }];
        }
    }

    /**
     * Gera PDF no estilo Monofloor com t√≥picos sem√¢nticos
     */
    private generateMonofloorPDF(data: {
        projectName: string;
        technicianName: string;
        visitDate: string;
        visitPurpose: string;
        observations: string;
        topicGroups: TopicGroup[];
    }): Promise<Buffer> {
        return new Promise((resolve, reject) => {
            const doc = new PDFDocument({
                size: 'A4',
                margins: { top: 60, bottom: 80, left: 50, right: 50 }
            });

            const chunks: Buffer[] = [];

            doc.on('data', (chunk) => chunks.push(chunk));
            doc.on('end', () => resolve(Buffer.concat(chunks)));
            doc.on('error', reject);

            // Cores Monofloor
            const colors = {
                gold: '#c9a962',
                gray: '#E5E5E5',
                darkGray: '#666666',
                black: '#000000'
            };

            let pageNumber = 1;

            // Fun√ß√£o para adicionar rodap√© com paleta de cores e n√∫mero de p√°gina
            const addFooter = () => {
                // Paleta de cores no rodap√©
                const paletteY = 770;
                const colorWidth = 115;
                const paletteColors = ['#1a1a1a', '#c9a962', '#8b7355', '#d4af6a', '#333333'];

                paletteColors.forEach((color, i) => {
                    doc.rect(50 + (i * colorWidth), paletteY, colorWidth, 15)
                        .fill(color);
                });

                // N√∫mero da p√°gina (caixa)
                doc.rect(520, paletteY, 25, 15)
                    .fill('#FFFFFF')
                    .stroke('#000000');

                doc.fontSize(9)
                    .fillColor('#000000')
                    .text(pageNumber.toString(), 520, paletteY + 3, {
                        width: 25,
                        align: 'center'
                    });

                pageNumber++;
            };

            // Fun√ß√£o para criar nova p√°gina com fundo cinza e cabe√ßalho
            const addNewPage = (isFirstPage: boolean = false) => {
                if (!isFirstPage) {
                    addFooter();
                    doc.addPage();
                }

                // Fundo cinza
                doc.rect(0, 0, 595, 842).fill(colors.gray);

                // Logo/Cabe√ßalho (placeholder - futuramente adicionar logo real)
                doc.fontSize(16)
                    .fillColor(colors.gold)
                    .font('Helvetica-Bold')
                    .text('MONOFLOOR REVESTIMENTOS', 50, 30, { align: 'left' });

                doc.fontSize(9)
                    .fillColor(colors.darkGray)
                    .font('Helvetica')
                    .text('Sistema STELION - Piso Monol√≠tico de Alto Desempenho', 50, 50);

                // Retornar √† posi√ß√£o inicial do conte√∫do
                doc.y = 90;
            };

            // P√ÅGINA 1 - Cabe√ßalho e Informa√ß√µes
            addNewPage(true);

            doc.fontSize(22)
                .fillColor(colors.gold)
                .font('Helvetica-Bold')
                .text('RELAT√ìRIO DE VISITA T√âCNICA', 50, 110, { align: 'center' });

            doc.moveDown(2);

            // Informa√ß√µes do projeto em caixa
            const infoBoxY = doc.y;
            doc.rect(50, infoBoxY, 495, 100)
                .fill('#FFFFFF')
                .stroke(colors.gold);

            doc.fontSize(11)
                .fillColor(colors.black)
                .font('Helvetica');

            const addInfoField = (label: string, value: string, y: number) => {
                doc.font('Helvetica-Bold').text(label, 70, y, { continued: true, width: 455 });
                doc.font('Helvetica').text(` ${value}`);
            };

            addInfoField('Projeto:', data.projectName, infoBoxY + 15);
            addInfoField('T√©cnico Respons√°vel:', data.technicianName, infoBoxY + 35);
            addInfoField('Data da Visita:', new Date(data.visitDate).toLocaleDateString('pt-BR'), infoBoxY + 55);
            addInfoField('Objetivo:', this.getVisitPurposeLabel(data.visitPurpose), infoBoxY + 75);

            doc.y = infoBoxY + 120;
            doc.moveDown(1);

            // Texto introdut√≥rio padr√£o
            doc.fontSize(10)
                .fillColor(colors.black)
                .font('Helvetica')
                .text(
                    'Este relat√≥rio apresenta a an√°lise t√©cnica realizada durante visita ao local, ' +
                    'com identifica√ß√£o das condi√ß√µes encontradas, problemas detectados e ' +
                    'recomenda√ß√µes t√©cnicas para aplica√ß√£o do sistema STELION. ' +
                    'As observa√ß√µes a seguir foram organizadas por √°rea ou tema t√©cnico.',
                    50,
                    doc.y,
                    { align: 'justify', width: 495 }
                );

            if (data.observations) {
                doc.moveDown(1);
                doc.fontSize(10)
                    .font('Helvetica-Bold')
                    .text('Observa√ß√µes Gerais:', 50, doc.y);
                doc.moveDown(0.3);
                doc.font('Helvetica')
                    .text(data.observations, 50, doc.y, { align: 'justify', width: 495 });
            }

            doc.moveDown(1.5);

            // Linha divis√≥ria
            doc.moveTo(50, doc.y).lineTo(545, doc.y).stroke(colors.gold);
            doc.moveDown(1);

            // T√ìPICOS
            data.topicGroups.forEach((topic, topicIndex) => {
                // Verificar se precisa de nova p√°gina
                if (doc.y > 650) {
                    addFooter();
                    doc.addPage();
                    addNewPage(false);
                }

                // N√∫mero e t√≠tulo do t√≥pico
                doc.fontSize(14)
                    .fillColor(colors.gold)
                    .font('Helvetica-Bold')
                    .text(`${topicIndex + 1}. ${topic.topic}`, 50, doc.y);

                doc.moveDown(0.5);

                // Descri√ß√£o do t√≥pico
                doc.fontSize(10)
                    .fillColor(colors.darkGray)
                    .font('Helvetica-Oblique')
                    .text(topic.description, 50, doc.y, { width: 495 });

                doc.moveDown(1);

                // Imagens e an√°lises do t√≥pico
                topic.frameAnalyses.forEach((item, frameIndex) => {
                    // Verificar espa√ßo para imagem + texto
                    if (doc.y > 550) {
                        addFooter();
                        doc.addPage();
                        addNewPage(false);
                    }

                    // Imagem em caixa branca
                    const imageBoxY = doc.y;
                    const imageBoxHeight = 220;

                    doc.rect(50, imageBoxY, 495, imageBoxHeight)
                        .fill('#FFFFFF')
                        .stroke(colors.darkGray);

                    try {
                        doc.image(item.frame.buffer, 55, imageBoxY + 5, {
                            fit: [485, 210],
                            align: 'center',
                            valign: 'center'
                        });
                    } catch (error) {
                        console.error('Erro ao adicionar imagem:', error);
                    }

                    doc.y = imageBoxY + imageBoxHeight + 10;

                    // An√°lise t√©cnica
                    doc.fontSize(10)
                        .fillColor(colors.black)
                        .font('Helvetica')
                        .text(item.analysis, 50, doc.y, {
                            align: 'justify',
                            width: 495
                        });

                    doc.moveDown(1.5);

                    // Linha divis√≥ria entre frames do mesmo t√≥pico
                    if (frameIndex < topic.frameAnalyses.length - 1) {
                        doc.moveTo(70, doc.y).lineTo(525, doc.y).stroke('#CCCCCC');
                        doc.moveDown(1);
                    }
                });

                // Linha divis√≥ria entre t√≥picos
                if (topicIndex < data.topicGroups.length - 1) {
                    doc.moveDown(1);
                    doc.moveTo(50, doc.y).lineTo(545, doc.y).stroke(colors.gold);
                    doc.moveDown(1.5);
                }
            });

            // P√ÅGINA FINAL
            addFooter();
            doc.addPage();
            addNewPage(false);

            doc.y = 350;

            doc.fontSize(14)
                .fillColor(colors.gold)
                .font('Helvetica-Bold')
                .text('CONSIDERA√á√ïES FINAIS', 50, doc.y, { align: 'center' });

            doc.moveDown(1.5);

            doc.fontSize(10)
                .fillColor(colors.black)
                .font('Helvetica')
                .text(
                    'Este relat√≥rio t√©cnico foi elaborado com base nas condi√ß√µes encontradas no momento da visita. ' +
                    'As recomenda√ß√µes apresentadas visam garantir a qualidade e durabilidade da aplica√ß√£o do sistema STELION. ' +
                    'Para esclarecimentos adicionais ou detalhamento de qualquer ponto, nossa equipe t√©cnica permanece √† disposi√ß√£o.',
                    50,
                    doc.y,
                    { align: 'justify', width: 495 }
                );

            doc.moveDown(2);

            doc.fontSize(9)
                .fillColor(colors.darkGray)
                .text(`Relat√≥rio gerado automaticamente em ${new Date().toLocaleString('pt-BR')}`, 50, doc.y, { align: 'center' });

            doc.moveDown(0.5);

            doc.fontSize(8)
                .text('Monofloor Revestimentos - Sistema de Relat√≥rios T√©cnicos Automatizados', 50, doc.y, { align: 'center' });

            // Rodap√© final
            addFooter();

            doc.end();
        });
    }

    /**
     * Gera PDF com imagens e an√°lises (vers√£o antiga - manter para compatibilidade)
     */
    private generatePDF(data: {
        projectName: string;
        technicianName: string;
        visitDate: string;
        visitPurpose: string;
        observations: string;
        analyses: FrameAnalysis[];
    }): Promise<Buffer> {
        return new Promise((resolve, reject) => {
            const doc = new PDFDocument({
                size: 'A4',
                margins: { top: 50, bottom: 50, left: 50, right: 50 }
            });

            const chunks: Buffer[] = [];

            doc.on('data', (chunk) => chunks.push(chunk));
            doc.on('end', () => resolve(Buffer.concat(chunks)));
            doc.on('error', reject);

            // Cabe√ßalho
            doc.fontSize(24)
                .fillColor('#c9a962')
                .text('RELAT√ìRIO DE VISITA T√âCNICA', { align: 'center' });

            doc.moveDown(0.5);
            doc.fontSize(14)
                .fillColor('#666666')
                .text('Monofloor Revestimentos', { align: 'center' });

            doc.moveDown(1.5);

            // Informa√ß√µes do projeto
            doc.fontSize(12).fillColor('#000000');

            const addField = (label: string, value: string) => {
                doc.font('Helvetica-Bold').text(label, { continued: true });
                doc.font('Helvetica').text(` ${value}`);
            };

            addField('Projeto:', data.projectName);
            addField('T√©cnico:', data.technicianName);
            addField('Data da Visita:', new Date(data.visitDate).toLocaleDateString('pt-BR'));
            addField('Objetivo:', this.getVisitPurposeLabel(data.visitPurpose));

            if (data.observations) {
                doc.moveDown(0.5);
                doc.font('Helvetica-Bold').text('Observa√ß√µes Gerais:');
                doc.font('Helvetica').text(data.observations);
            }

            doc.moveDown(1);
            doc.moveTo(50, doc.y).lineTo(545, doc.y).stroke('#cccccc');
            doc.moveDown(1);

            // An√°lises com imagens
            data.analyses.forEach((item, index) => {
                // Verificar se precisa de nova p√°gina
                if (doc.y > 600) {
                    doc.addPage();
                }

                // Timestamp
                doc.fontSize(14)
                    .fillColor('#c9a962')
                    .font('Helvetica-Bold')
                    .text(`${index + 1}. An√°lise aos ${this.formatTimestamp(item.frame.timestamp)}`);

                doc.moveDown(0.5);

                // Imagem
                try {
                    const imageWidth = 500;
                    const imageHeight = 280;

                    doc.image(item.frame.buffer, {
                        fit: [imageWidth, imageHeight],
                        align: 'center'
                    });

                    doc.moveDown(0.5);
                } catch (error) {
                    console.error('Erro ao adicionar imagem ao PDF:', error);
                }

                // An√°lise
                doc.fontSize(11)
                    .fillColor('#000000')
                    .font('Helvetica')
                    .text(item.analysis, {
                        align: 'justify'
                    });

                doc.moveDown(1);

                // Linha divis√≥ria
                if (index < data.analyses.length - 1) {
                    doc.moveTo(50, doc.y).lineTo(545, doc.y).stroke('#eeeeee');
                    doc.moveDown(1);
                }
            });

            // Rodap√© final
            doc.addPage();
            doc.fontSize(12).fillColor('#666666');
            doc.text('Fim do Relat√≥rio', { align: 'center' });
            doc.moveDown(0.5);
            doc.fontSize(10);
            doc.text(`Gerado automaticamente em ${new Date().toLocaleString('pt-BR')}`, { align: 'center' });
            doc.text('Monofloor Revestimentos - Sistema de Relat√≥rios Autom√°ticos', { align: 'center' });

            doc.end();
        });
    }

    /**
     * Gera PDF consolidado com m√∫ltiplos v√≠deos usando an√°lise sem√¢ntica
     */
    private async generateConsolidatedPDF(data: {
        projectName: string;
        technicianName: string;
        visitDate: string;
        visitPurpose: string;
        observations: string;
        videos: Array<{
            videoNumber: number;
            videoName: string;
            analyses: FrameAnalysis[];
        }>;
        outputFormat?: 'pdf' | 'docx';
        clientName?: string;
        address?: string;
    }): Promise<Buffer> {
        console.log('[VideoReport] Consolidando an√°lises de m√∫ltiplos v√≠deos...');

        // Combinar todas as an√°lises de todos os v√≠deos
        const allAnalyses: FrameAnalysis[] = [];
        data.videos.forEach(video => {
            allAnalyses.push(...video.analyses);
        });

        console.log(`[VideoReport] Total de ${allAnalyses.length} an√°lises de ${data.videos.length} v√≠deos`);

        // Agrupar por t√≥picos sem√¢nticos (todos os v√≠deos juntos)
        const topicGroups = await this.groupFramesByTopics(allAnalyses);

        const format = data.outputFormat || 'pdf';

        // Gerar no formato escolhido
        if (format === 'docx') {
            console.log('[VideoReport] Gerando DOCX consolidado...');
            return docxReportService.generateDocxReport({
                projectName: data.projectName,
                technicianName: data.technicianName,
                visitDate: data.visitDate,
                clientName: data.clientName || data.projectName,
                address: data.address || '',
                topicGroups
            });
        } else {
            console.log('[VideoReport] Gerando PDF consolidado...');
            return this.generateMonofloorPDF({
                projectName: data.projectName,
                technicianName: data.technicianName,
                visitDate: data.visitDate,
                visitPurpose: data.visitPurpose,
                observations: data.observations,
                topicGroups
            });
        }
    }

    /**
     * Gera PDF consolidado com m√∫ltiplos v√≠deos (vers√£o antiga - deprecated)
     */
    private generateConsolidatedPDF_OLD(data: {
        projectName: string;
        technicianName: string;
        visitDate: string;
        visitPurpose: string;
        observations: string;
        videos: Array<{
            videoNumber: number;
            videoName: string;
            analyses: FrameAnalysis[];
        }>;
    }): Promise<Buffer> {
        return new Promise((resolve, reject) => {
            const doc = new PDFDocument({
                size: 'A4',
                margins: { top: 50, bottom: 50, left: 50, right: 50 }
            });

            const chunks: Buffer[] = [];

            doc.on('data', (chunk) => chunks.push(chunk));
            doc.on('end', () => resolve(Buffer.concat(chunks)));
            doc.on('error', reject);

            // Cabe√ßalho
            doc.fontSize(24)
                .fillColor('#c9a962')
                .text('RELAT√ìRIO DE VISITA T√âCNICA', { align: 'center' });

            doc.moveDown(0.5);
            doc.fontSize(14)
                .fillColor('#666666')
                .text('Monofloor Revestimentos', { align: 'center' });

            doc.moveDown(1.5);

            // Informa√ß√µes do projeto
            doc.fontSize(12).fillColor('#000000');

            const addField = (label: string, value: string) => {
                doc.font('Helvetica-Bold').text(label, { continued: true });
                doc.font('Helvetica').text(` ${value}`);
            };

            addField('Projeto:', data.projectName);
            addField('T√©cnico:', data.technicianName);
            addField('Data da Visita:', new Date(data.visitDate).toLocaleDateString('pt-BR'));
            addField('Objetivo:', this.getVisitPurposeLabel(data.visitPurpose));
            addField('Total de V√≠deos:', `${data.videos.length} v√≠deo${data.videos.length > 1 ? 's' : ''}`);

            if (data.observations) {
                doc.moveDown(0.5);
                doc.font('Helvetica-Bold').text('Observa√ß√µes Gerais:');
                doc.font('Helvetica').text(data.observations);
            }

            doc.moveDown(1);
            doc.moveTo(50, doc.y).lineTo(545, doc.y).stroke('#cccccc');
            doc.moveDown(1);

            // Processar cada v√≠deo
            data.videos.forEach((video, videoIndex) => {
                // Cabe√ßalho do v√≠deo
                if (videoIndex > 0) {
                    doc.addPage();
                }

                doc.fontSize(18)
                    .fillColor('#c9a962')
                    .font('Helvetica-Bold')
                    .text(`üìπ V√≠deo ${video.videoNumber}`, { align: 'left' });

                doc.moveDown(0.3);
                doc.fontSize(11)
                    .fillColor('#888888')
                    .font('Helvetica')
                    .text(`${video.videoName}`, { align: 'left' });

                doc.moveDown(1);
                doc.moveTo(50, doc.y).lineTo(545, doc.y).stroke('#cccccc');
                doc.moveDown(1);

                // An√°lises do v√≠deo
                video.analyses.forEach((item, index) => {
                    // Verificar se precisa de nova p√°gina
                    if (doc.y > 600) {
                        doc.addPage();
                    }

                    // Timestamp
                    doc.fontSize(14)
                        .fillColor('#c9a962')
                        .font('Helvetica-Bold')
                        .text(`${index + 1}. An√°lise aos ${this.formatTimestamp(item.frame.timestamp)}`);

                    doc.moveDown(0.5);

                    // Imagem
                    try {
                        const imageWidth = 500;
                        const imageHeight = 280;

                        doc.image(item.frame.buffer, {
                            fit: [imageWidth, imageHeight],
                            align: 'center'
                        });

                        doc.moveDown(0.5);
                    } catch (error) {
                        console.error('Erro ao adicionar imagem ao PDF:', error);
                    }

                    // An√°lise
                    doc.fontSize(11)
                        .fillColor('#000000')
                        .font('Helvetica')
                        .text(item.analysis, {
                            align: 'justify'
                        });

                    doc.moveDown(1);

                    // Linha divis√≥ria
                    if (index < video.analyses.length - 1) {
                        doc.moveTo(50, doc.y).lineTo(545, doc.y).stroke('#eeeeee');
                        doc.moveDown(1);
                    }
                });

                // Separador entre v√≠deos
                if (videoIndex < data.videos.length - 1) {
                    doc.moveDown(2);
                    doc.moveTo(50, doc.y).lineTo(545, doc.y).stroke('#c9a962');
                    doc.moveDown(1);
                }
            });

            // Rodap√© final
            doc.addPage();
            doc.fontSize(12).fillColor('#666666');
            doc.text('Fim do Relat√≥rio', { align: 'center' });
            doc.moveDown(0.5);
            doc.fontSize(10);
            doc.text(`Gerado automaticamente em ${new Date().toLocaleString('pt-BR')}`, { align: 'center' });
            doc.text('Monofloor Revestimentos - Sistema de Relat√≥rios Autom√°ticos', { align: 'center' });

            doc.end();
        });
    }

    /**
     * Limpa frames tempor√°rios
     */
    private async cleanupFrames(frames: ExtractedFrame[]) {
        for (const frame of frames) {
            try {
                await fs.unlink(frame.path);
            } catch (error) {
                console.error('Erro ao deletar frame:', error);
            }
        }
    }

    /**
     * Formata timestamp para MM:SS
     */
    private formatTimestamp(seconds: number): string {
        const mins = Math.floor(seconds / 60);
        const secs = seconds % 60;
        return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
    }

    /**
     * Retorna label do objetivo da visita
     */
    private getVisitPurposeLabel(purpose: string): string {
        const labels: Record<string, string> = {
            vistoria: 'Vistoria Inicial',
            acompanhamento: 'Acompanhamento de Obra',
            problema: 'Identifica√ß√£o de Problema',
            finaliza√ß√£o: 'Vistoria de Finaliza√ß√£o',
            manutencao: 'Manuten√ß√£o',
            outro: 'Outro'
        };
        return labels[purpose] || purpose;
    }
}

export default new VideoReportService();
